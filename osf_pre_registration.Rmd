---
title: "Preferring Politeness - OSF Pre-Registration"
author: "Hannah E. Marshall, Rondeline M. Williams, and Michael C. Frank"
date: "9/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=TRUE, message=FALSE, warning=FALSE)
```

```{r load libraries, include=FALSE}
library(BayesFactor)
library(tidybayes)
library(mgcv)
library(stringi)
library(VGAM)
library(brms)
library(broom)
library(glmmfields)
library(generics)
library(broom.mixed)
library(tidyverse)
```

### Study Information

**1. Title (required)** 

Preferring politeness: Young children’s implicit understanding of linguistic politeness

**2. Authors (required)**

Hannah E. Marshall, Rondeline M. Williams, and Michael C. Frank

Department of Psychology, Stanford University

**3. Description (optional)**

To date, there is evidence of children reliably indicating preference for a polite speaker by 4 years (Yoon & Frank, 2019). However, previous studies have not observed reliable preference for a polite speaker in children younger than 4 years, potentially due to experimental task demands. We have developed a less challenging task, which may detect preference for a polite speaker in children younger than 4 years. Using this task, we will test 2-year-old, 3-year-old, and 4-year-old children for preference for a polite speaker.

The task we have developed is based on shape-preference paradigms used by Hamlin, Wynn, and Bloom (2007) and Thomas and Sarnecka (2019) to study social evaluation in the contexts of helping behavior and social status respectively.

**4. Hypotheses (required)**

Considering our less challenging task, we predict that 2-year-old, 3-year-old, and 4-year-old children will indicate preference for a polite speaker over an impolite speaker (i.e. the proportion of children in each age category who indicate preference for a polite speaker will differ significantly from chance). 

Considering evidence for graded comprehension of politeness in young children (Yoon & Frank, 2019), we predict that children will indicate preference for a polite speaker over an impolite speaker more reliably (i.e. with a stronger effect) with increasing age.

### Design Plan

**5. Study type (required)**

Experiment

**6. Blinding (required)**

For studies that involve human subjects, they will not know the treatment group to which they have been assigned.

**7. Is there any additional blinding in this study?**

None.

**8. Study design (required)**

We have created a within-subjects design with 1 factor (preference by age) where age is treated as both continuous and categorical (by age category).

_Stimuli_

The animation will begin with a (secondary) familiarization phase in which a shape (the speaker) enters from the left of the screen, spots two cookies on the opposite side of the screen, gasps excitedly, approaches the cookies, eats one cookie, and celebrates by jumping up and down. This phase will inform the participant that the speaker’s goal is to eat a cookie.

A testing phase will follow in which the speaker enters from the left of the screen and stops in front of another shape (the listener), who is standing in the way of the cookies. In the polite condition, the speaker will say, “I am so hungry! May I have a cookie please?” In the impolite condition, the speaker will say, “I am so hungry! Give me a cookie now.” Regardless of condition, the listener will move out of the speaker’s way. The speaker will gasp excitedly, cross in front of the listener, approach the cookies, eat one cookie, and celebrate by jumping up and down. 

Utterances will be prerecorded. Intonation will be naturalistic and will not include exaggerated “polite” or “impolite” prosody. Utterances will be cleaned using Audacity (an audio editing and recording software) and RMS will be standardized across conditions using Praat (a phonetics software).

The background will consist of a green block and blue block depicting grass and sky. The listener will always be a blue circle. The polite and impolite speakers will consist of either a red triangle and yellow square or a yellow triangle and red square. The shape of the speaker (triangle/square), color of the shape (red/yellow), and order of the conditions (first/second) will be counterbalanced across trials.

_Procedure_

Testing will take place online through Zoom (a videotelephony software developed and provided by Zoom Video Communications). Test trials will be recorded with parental consent. Each session will begin by testing audio quality, testing video quality, and calibrating the participant’s screen settings.

The experimenter will begin with a warm-up activity to build rapport with the child. The experimenter will play a short "I-Spy" game with the child during which a black and white dog will emerge from behind a pile of leaves, then a brown squirrel will emerge from the same pile. The animals will be front-facing and centered and the pile of leaves will be symmetrical to avoid inducing side bias.

Next, the experimenter will introduce the child to a green pentagon with eyes and a mouth to indicate animateness. The experimenter will then show the child what the character looks like when it “feels very sad” (downturned mouth), “feels normal” (flat-line mouth), and “feels very happy” (upturned, open mouth). The purpose of this primary familiarization phase will be to introduce shapes as animate characters and to accustom the participant to facial expressions that will be used in the animation.

After this primary familiarization phase, the animation will be played. Each participant will see both the polite condition and the impolite condition as detailed above. The experimenter will not be blind to condition but will bear a blank expression and look down while the animation is playing. At the end of the animation, the caregiver attending to the child will be asked to close their eyes before the child’s preference and reasoning are assessed.

**9. Randomization (optional)**

A generic list randomizer will be used to assign the first 16 participants in each age category to one of 16 unique animations (without repeats), which account for all necessary counterbalanced conditions. The same generic list randomizer will be used to assign the remaining 4 participants in each age category to one of the 16 unique animations (without repeats).

### Sampling Plan

**10. Existing data (required)**

Registration prior to creation of data: As of the date of submission of this research plan for preregistration, the data have not yet been collected, created, or realized. 

**11. Explanation of existing data (optional)**

Not applicable

**12. Data collection procedures (required)**

Participants will include 2-year old, 3-year-old, and 4-year-old children living in the U.S. at the time of data collection. Participants will be recruited through the Department of Psychology at Stanford University from Children Helping Science (an online recruitment platform for developmental research), Facebook advertisements, and direct outreach to preschools and daycares in the Bay Area. 

A parent must provide either written consent via email or verbal consent prior to testing. The attending parent will be notified that they or the child may stop participation at any time. Children will complete the study on their family’s home or personal computers with an experimenter via Zoom. Testing sessions will be recorded with parental consent. Children will listen to the experimenter, watch the animation, and answer two questions verbally or by indicating their answer by pointing or reaching. The recording will be used to code the child's responses.

Including screen setup and debriefing, each session should take 10 to 15 minutes to complete. Children nor parents will be financially compensated for participating in the study.

A child will be excluded if:

1. The child is known to have any cognitive, auditory, or visual impairment, and the impairment is reported by the parent.
2. The child is known to have any neurodevelopmental disorder that significantly affects cognitive processing or social cognition, such as down syndrome or autism spectrum disorder, and the disorder is reported by the parent. Attention deficit disorder and attention deficit hyperactivity disorder will only be grounds for exclusion if the child is unable to adequately complete test trials due to inattention or restlessness as per criteria 6.
3. The child does not hear English “all of the time” or “most of the time” as indicated by the parent upon registration.
4. A non-participant (e.g. the child’s parent or sibling) interjects or interferes by pointing at the screen at any time during the experiment, audibly commenting, or providing a response to either dependent variable measure (DV).
5. The child fails to provide a response to DV1 after four prompts.
6. The child is looking away from the screen for at least 25% of the animation.
7. The child is looking away from the screen during either speaker utterance.
8. The parent rates the video or audio quality below a 3 out of 5.

Parents will also be asked to report their child’s gender, their child’s race, their child's first language, and whether their child has siblings, which may all be used as covariates in exploratory analyses.

**13. Sample size (required)**

Our target sample size is N=60 (n=20 in each age category).

**14. Sample size rationale (optional)**

We selected our sample size based on a Bayesian power analysis conducted in R (code below). Our lowest-power tests will be by-age-category Bayesian binomial tests. To detect an effect in which 80% of children indicate preference for a polite speaker with 80% power and a 95% credible interval, we must run 15 participants in each age category (45 total). We will run 60 participants to compensate for exclusions and missing data.

```{r define variables}
N <- 15
success_probability <- 0.8
```

```{r simulate data, results="hide"}
set.seed(3)
sim_data <-tibble(y=rbinom(n=N, size=1, prob=success_probability))
```

```{r model with iterations, results="hide"}
fit <- brm(data=sim_data, family=binomial, y|trials(1)~1, prior(normal(0,2), class=Intercept), seed=3)
```

```{r extract posterior draws, results="hide"}
probability_draws <- posterior_samples(fit) %>% 
  transmute(p=inv_logit_scaled(b_Intercept))
```

```{r posterior intervals, results="hide"}
median_qi(probability_draws)
```

```{r write and run simulation function, results="hide"}
sim_function <- function(seed, n_participants) {
  
  n_trials <- 1
  prob_hit <- success_probability
  
  set.seed(seed)
  
  sim_data <- tibble(y = rbinom(n = n_participants, size = n_trials, prob = prob_hit))
  
  update(fit, newdata = sim_data, seed = seed) %>% 
  posterior_samples() %>% 
  transmute(p = inv_logit_scaled(b_Intercept)) %>% 
  median_qi() %>% 
  select(.lower:.upper)
  
}

#Argument "seed" should be set to 1:1000+ but is temporarily set to 1:10 for ease running simulation while editing code.

iterations <- 
  tibble(seed=1:10) %>% 
  mutate(ci=map(seed, sim_function, n_participants=N)) %>% 
  unnest(cols=c(ci))
```

```{r power}
null <- 0.5

iterations %>% 
  mutate(reject_the_null = null < .lower | null > .upper) %>% 
  summarise(power = mean(reject_the_null))
```
A second power analysis (code below) showed that with 60 participants, across age categories, we can detect an effect in which 70% of children indicate preference for a polite speaker with 80% power and a 95% credible interval.

```{r define variables 2}
N2 <- 60
success_probability2 <- 0.7
```

```{r simulate data 2, results="hide"}
set.seed(3)
sim_data2 <-tibble(y=rbinom(n=N2, size=1, prob=success_probability2))
```

```{r model with iterations 2, results="hide"}
fit2 <- brm(data=sim_data2, family=binomial, y|trials(1)~1, prior(normal(0,2), class=Intercept), seed=3)
```

```{r extract posterior draws 2, results="hide"}
probability_draws2 <- posterior_samples(fit2) %>% 
  transmute(p=inv_logit_scaled(b_Intercept))
```

```{r posterior intervals 2, results="hide"}
median_qi(probability_draws2)
```

```{r write and run simulation function 2, results="hide"}
sim_function2 <- function(seed, n_participants2) {
  
  n_trials2 <- 1
  prob_hit2 <- success_probability2
  
  set.seed(seed)
  
  sim_data2 <- tibble(y = rbinom(n = n_participants2, size = n_trials2, prob = prob_hit2))
  
  update(fit2, newdata = sim_data2, seed = seed) %>% 
  posterior_samples() %>% 
  transmute(p = inv_logit_scaled(b_Intercept)) %>% 
  median_qi() %>% 
  select(.lower:.upper)
  
}

#Argument "seed" should be set to 1:1000+ but is temporarily set to 1:10 for ease running simulation while editing code.

iterations2 <- 
  tibble(seed=1:10) %>% 
  mutate(ci=map(seed, sim_function2, n_participants2=N2)) %>% 
  unnest(cols=c(ci))
```

```{r power 2}
null2 <- 0.5

iterations2 %>% 
  mutate(reject_the_null2 = null2 < .lower | null2 > .upper) %>% 
  summarise(power2 = mean(reject_the_null2))
```

**15. Stopping rule (optional)**

Because participant recruitment will be conducted centrally by the Department of Psychology at Stanford University, we should be able to run our exact target sample size.

### Variables

**16. Manipulated variables (optional)**

Participants’ age will be the independent variable. Although age is continuous, we will also treat it as a categorical variable with three levels: 

- 2-year-olds (2 years, 0 months ⩽ x < 3 years, 0 months)
- 3-year-olds (3 years, 0 months ⩽ x <  4 years, 0 months)
- 4-year-olds (4 years, 0 months ⩽  x < 5 years, 0 months)

**17. Measured variables (required)**

We will measure preference between a polite speaker and an impolite speaker by presenting a forced-choice in which the speakers appear on opposite sides of the screen (counterbalanced) and the participant is asked, “Which friend do you want to play with?” (DV1, our key DV). Pointing, reaching, and verbal answers will be coded equivalently as indication of preference. If a child does not answer, the child will be prompted three more times with analogous wording. If the child does not provide an answer, the session will be concluded.

If the child provides an answer, the child will be asked, “Why do you want to play with that friend?” (DV2, which may be used in exploratory analyses). If the child does not provide an answer, the child will be prompted twice more.

**18. Indices (optional)**

Not applicable

### Analysis Plan

**19. Statistical models (required)**

We intend to run a Bayesian binomial test from the BayesianFirstAid package in R to assess whether the proportion of children in our sample who indicate preference for a polite speaker differs from chance. 

```{r count speaker preference, eval=FALSE}
#Create frequency matrix to pull values from when running Bayesian binomial tests.

speaker_matrix <- table(pp_data$age_category, pp_data$speaker_preference)
print(speaker_matrix)
```

```{r Bayesian binomial test, eval=FALSE}
binomial_test <- bayes.binom.test(x=speaker_matrix["2","1"] + speaker_matrix["3","1"] + speaker_matrix["4","1"], n=nrow(pp_data), comp.theta=0.5, cred.mass=0.95)
```

We intend to run three more Bayesian binomial tests from the BayesianFirstAid package in R to assess whether the proportion of children in each age category who indicate preference for a polite speaker differs from chance.

```{r Bayesian binomial test 2s, eval=FALSE}
binomial_test2 <- bayes.binom.test(x=speaker_matrix["2","1"], n=speaker_matrix["2","0"] + speaker_matrix["2","1"], comp.theta=0.5, cred.mass=0.95)
```

```{r Bayesian binomial test 3s, eval=FALSE}
binomial_test3 <- bayes.binom.test(x=speaker_matrix["3","1"], n=speaker_matrix["3","0"] + speaker_matrix["3","1"], comp.theta=0.5, cred.mass=0.95)
```

```{r Bayesian binomial test 4s, eval=FALSE}
binomial_test4 <- bayes.binom.test(x=speaker_matrix["4","1"], n=speaker_matrix["4","0"] + speaker_matrix["4","1"], comp.theta=0.5, cred.mass=0.95)
```

We intend to run a Bayesian logistic regression model from the rstanarm package in R to model speaker preference (DV1) as a function of age.

```{r DV1 logistic model, eval=FALSE}
DV1_model <- stan_glm(speaker_preference~age, family=binomial(), data=pp_data)
```

_Key_

- speaker_matrix: frequency matrix of speaker preference by age
- pp_data: Preferring Politeness data frame
- age_category: age grouped by years
- speaker_preference: speaker preference (0 = impolite, 1 = polite)
- binomial_test: Bayesian binomial test across age categories
- binomial_test2: Bayesian binomial test for 2-year-old age category
- binomial_test3: Bayesian binomial test for 3-year-old age category
- binomial_test4: Bayesian binomial test for 4-year-old age category
- DV1_model: Bayesian logistic regression model of speaker preference as a function of age
- age: age

**20. Transformations (optional)**

Where age is categorically described, it will be coded to consist of three levels: 

- 2-year-olds (2 years, 0 months ⩽ x < 3 years, 0 months)
- 3-year-olds (3 years, 0 months ⩽ x <  4 years, 0 months)
- 4-year-olds (4 years, 0 months ⩽  x < 5 years, 0 months)

DV1 (preference) will be dummy coded with preference for the polite speaker as 1 and preference for the impolite speaker as 0.

DV2 will be coded to include:

1. No reasoning: no explanation after a third prompt (e.g. silence, shrugging, or “I don’t know”).
2. Superficial reasoning: any explanation regarding elements besides speaker utterance (e.g. “I like him”, "He's red", "Triangles are my favorite").
3. Logical reasoning: any explanation that refers to speaker utterance and is consistent with the animation (e.g. describing the polite speaker as “nice” or “polite”).
4. Other reasoning: any explanation that does not fall under classifications 1 – 3.

**21. Inference criteria (optional)**

We will make inferences based on credible intervals. We will use a 95% credible interval criterion for success.

Two-tailed tests will be used for each of our analyses.

**22. Data exclusion (optional)**

No checks will be performed to determine eligibility for inclusion besides those outlined in "12. Data collection procedures" and verification that each subject answered DV1. 

All data-based outliers will be included in analyses. 

**23. Missing data (optional)**

Our study will use pairwise deletion. If a child does not complete DV2, their DV1 data will be included in analyses. If a child does not complete DV1, that child will be excluded from analyses.

**24. Exploratory analysis (optional)**

Not applicable

### Other

**25. Other (Optional)**

_Works Cited_

- Hamlin, J. K., Wynn, K., & Bloom, P. (2007). Social evaluation by preverbal infants. Nature, 450(7169), 557-559.
- Thomas, A. J., & Sarnecka, B. W. (2019). Infants choose those who defer in conflicts. Current Biology, 29(13), 2183-2189.
- Yoon, E. J., & Frank, M. C. (2019). Children's understanding of polite requests.
